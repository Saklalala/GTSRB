{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4dd4526-749c-4059-b228-9a7f981b1bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on EDA, we do feature engineering at this notebook\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import local_binary_pattern, hog\n",
    "from skimage import filters, morphology, measure\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8f65b6a-7579-44e6-bdfa-1b16d34bb22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract new feature set (HOG on Digit ROI, Projection Profiles, LBP)\n",
    "# target to get features which are beneficial to detect speed limit signs\n",
    "def detect_digit_roi(img, min_area=50):\n",
    "    \"\"\"\n",
    "    detect potential digit regions in traffic signs\n",
    "    focus on central regions and areas with high contrast\n",
    "    \"\"\"\n",
    "    # convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # apply adaptive thresholding to highlight text/digits\n",
    "    thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                                   cv2.THRESH_BINARY_INV, 11, 2)\n",
    "    \n",
    "    # find contours\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # filter contours by area and aspect ratio (digits tend to be taller than wide)\n",
    "    digit_rois = []\n",
    "    img_center_x, img_center_y = img.shape[1] // 2, img.shape[0] // 2\n",
    "    \n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area > min_area:\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            aspect_ratio = h / w if w > 0 else 0\n",
    "            \n",
    "            # check if it's in central region and has digit-like aspect ratio\n",
    "            center_dist = np.sqrt((x + w/2 - img_center_x)**2 + (y + h/2 - img_center_y)**2)\n",
    "            max_dist = min(img.shape[0], img.shape[1]) * 0.4\n",
    "            \n",
    "            if center_dist < max_dist and 0.5 <= aspect_ratio <= 3.0:\n",
    "                # extract ROI\n",
    "                roi = gray[y:y+h, x:x+w]\n",
    "                if roi.size > 0:\n",
    "                    digit_rois.append(roi)\n",
    "    \n",
    "    # if no ROIs found, use central region\n",
    "    if not digit_rois:\n",
    "        h, w = gray.shape\n",
    "        center_h, center_w = h // 3, w // 3\n",
    "        roi = gray[center_h:2*center_h, center_w:2*center_w]\n",
    "        if roi.size > 0:\n",
    "            digit_rois.append(roi)\n",
    "    \n",
    "    return digit_rois\n",
    "\n",
    "def extract_hog_from_digit_roi(img):\n",
    "    \"\"\"extract HOG features from detected digit ROIs\"\"\"\n",
    "    digit_rois = detect_digit_roi(img)\n",
    "    \n",
    "    hog_features = []\n",
    "    for roi in digit_rois:\n",
    "        # resize ROI to standard size for consistent HOG extraction\n",
    "        if roi.size > 0:\n",
    "            roi_resized = cv2.resize(roi, (32, 32))\n",
    "            # extract HOG features\n",
    "            hog_feat = hog(roi_resized, orientations=9, pixels_per_cell=(8, 8),\n",
    "                          cells_per_block=(2, 2), block_norm='L2-Hys', \n",
    "                          feature_vector=True)\n",
    "            hog_features.extend(hog_feat)\n",
    "    \n",
    "    # if no features extracted, return zeros\n",
    "    if not hog_features:\n",
    "        hog_features = [0] * 36  # Standard HOG feature size for 32x32 image\n",
    "    \n",
    "    # pad or truncate to fixed size (36 features)\n",
    "    if len(hog_features) > 36:\n",
    "        hog_features = hog_features[:36]\n",
    "    elif len(hog_features) < 36:\n",
    "        hog_features.extend([0] * (36 - len(hog_features)))\n",
    "    \n",
    "    return hog_features\n",
    "\n",
    "def extract_projection_profiles(img):\n",
    "    \"\"\"extract horizontal and vertical projection profiles\"\"\"\n",
    "    # convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # apply edge detection to highlight text/digit boundaries\n",
    "    edges = cv2.Canny(gray, 50, 150)\n",
    "    \n",
    "    # calculate projection profiles\n",
    "    h_profile = np.sum(edges, axis=1)  # horizontal projection (sum across width)\n",
    "    v_profile = np.sum(edges, axis=0)  # vertical projection (sum across height)\n",
    "    \n",
    "    # normalize profiles\n",
    "    h_profile = h_profile / (np.sum(h_profile) + 1e-8)\n",
    "    v_profile = v_profile / (np.sum(v_profile) + 1e-8)\n",
    "    \n",
    "    # extract statistical features from profiles\n",
    "    def profile_stats(profile):\n",
    "        if len(profile) == 0:\n",
    "            return [0, 0, 0, 0, 0]\n",
    "        \n",
    "        # basic statistics\n",
    "        mean_val = np.mean(profile)\n",
    "        std_val = np.std(profile)\n",
    "        max_val = np.max(profile)\n",
    "        \n",
    "        # peak detection (local maxima)\n",
    "        peaks = []\n",
    "        for i in range(1, len(profile) - 1):\n",
    "            if profile[i] > profile[i-1] and profile[i] > profile[i+1]:\n",
    "                peaks.append(profile[i])\n",
    "        \n",
    "        num_peaks = len(peaks)\n",
    "        peak_intensity = np.mean(peaks) if peaks else 0\n",
    "        \n",
    "        return [mean_val, std_val, max_val, num_peaks, peak_intensity]\n",
    "    \n",
    "    h_stats = profile_stats(h_profile)\n",
    "    v_stats = profile_stats(v_profile)\n",
    "    \n",
    "    # combine horizontal and vertical statistics\n",
    "    projection_features = h_stats + v_stats\n",
    "    \n",
    "    return projection_features\n",
    "\n",
    "def extract_lbp_features(img):\n",
    "    \"\"\"extract Local Binary Pattern features\"\"\"\n",
    "    # convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # extract LBP\n",
    "    radius = 1\n",
    "    n_points = 8 * radius\n",
    "    lbp = local_binary_pattern(gray, n_points, radius, method='uniform')\n",
    "    \n",
    "    # calculate histogram of LBP\n",
    "    n_bins = n_points + 2  # uniform patterns + non-uniform\n",
    "    hist, _ = np.histogram(lbp.ravel(), bins=n_bins, range=(0, n_bins))\n",
    "    \n",
    "    # normalize histogram\n",
    "    hist = hist.astype(np.float32)\n",
    "    hist /= (hist.sum() + 1e-8)\n",
    "    \n",
    "    return hist.tolist()\n",
    "\n",
    "def extract_new_features_for_images(image_paths, base_path, dataset_name=\"\"):\n",
    "    \"\"\"extract all new features for a list of images\"\"\"\n",
    "    all_features = []\n",
    "    \n",
    "    for img_path in tqdm(image_paths, desc=f\"Extracting new features ({dataset_name})\"):\n",
    "        full_path = os.path.join(base_path, img_path)\n",
    "        \n",
    "        try:\n",
    "            # read image\n",
    "            img = cv2.imread(full_path)\n",
    "            if img is None:\n",
    "                print(f\"Could not read image: {full_path}\")\n",
    "                # Create zero features\n",
    "                hog_digit_features = [0] * 36\n",
    "                projection_features = [0] * 10\n",
    "                lbp_features = [0] * 10\n",
    "            else:\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                \n",
    "                # extract features\n",
    "                hog_digit_features = extract_hog_from_digit_roi(img)\n",
    "                projection_features = extract_projection_profiles(img)\n",
    "                lbp_features = extract_lbp_features(img)\n",
    "            \n",
    "            # combine all features\n",
    "            combined_features = hog_digit_features + projection_features + lbp_features\n",
    "            combined_features.insert(0, img_path)  # Add image path as first column\n",
    "            all_features.append(combined_features)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_path}: {e}\")\n",
    "            # create zero features\n",
    "            hog_digit_features = [0] * 36\n",
    "            projection_features = [0] * 10\n",
    "            lbp_features = [0] * 10\n",
    "            combined_features = hog_digit_features + projection_features + lbp_features\n",
    "            combined_features.insert(0, img_path)\n",
    "            all_features.append(combined_features)\n",
    "    \n",
    "    return all_features\n",
    "\n",
    "# 2: using the pretrained CNN to extract deep features\n",
    "\n",
    "def preprocess_image_for_cnn(img, target_size=(224, 224)):\n",
    "    \"\"\"Preprocess image for CNN feature extraction\"\"\"\n",
    "    # resize image first\n",
    "    img_resized = cv2.resize(img, target_size)\n",
    "    \n",
    "    # convert to array and expand dims for batch processing\n",
    "    img_array = image.img_to_array(img_resized)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    \n",
    "    # preprocess for ResNet50\n",
    "    img_array = preprocess_input(img_array)\n",
    "    \n",
    "    return img_array\n",
    "\n",
    "def extract_deep_features_for_images(image_paths, base_path, base_model, dataset_name=\"\"):\n",
    "    \"\"\"extract deep features using pre-trained ResNet50\"\"\"\n",
    "    all_features = []\n",
    "    \n",
    "    for img_path in tqdm(image_paths, desc=f\"Extracting deep features ({dataset_name})\"):\n",
    "        full_path = os.path.join(base_path, img_path)\n",
    "        \n",
    "        try:\n",
    "            # read and preprocess image\n",
    "            img = cv2.imread(full_path)\n",
    "            if img is None:\n",
    "                print(f\"Could not read image: {full_path}\")\n",
    "                # create zero features (ResNet50 outputs 2048 features)\n",
    "                deep_features = [0] * 2048\n",
    "            else:\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                img_preprocessed = preprocess_image_for_cnn(img)\n",
    "                \n",
    "                # extract features\n",
    "                features = base_model.predict(img_preprocessed, verbose=0)\n",
    "                deep_features = features.flatten().tolist()\n",
    "            \n",
    "            # add image path as first column\n",
    "            deep_features.insert(0, img_path)\n",
    "            all_features.append(deep_features)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_path}: {e}\")\n",
    "            # create zero features\n",
    "            deep_features = [0] * 2048\n",
    "            deep_features.insert(0, img_path)\n",
    "            all_features.append(deep_features)\n",
    "    \n",
    "    return all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e301b3ab-f1a8-41f5-ad44-7a41e2bef978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training metadata...\n",
      "Loaded train metadata for 5488 images\n",
      "Loading test metadata...\n",
      "Loaded test metadata for 2353 images\n",
      "Processing 5488 training images and 2353 test images...\n",
      "Processing training set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting new features (Train): 100%|████| 5488/5488 [00:03<00:00, 1725.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting new features (Test): 100%|█████| 2353/2353 [00:01<00:00, 1756.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train new features shape: (5488, 57)\n",
      "Test new features shape: (2353, 57)\n",
      "New features extracted successfully for both sets!\n",
      "Loading pre-trained ResNet50 model...\n",
      "Processing training set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting deep features (Train): 100%|█████| 5488/5488 [04:15<00:00, 21.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting deep features (Test): 100%|██████| 2353/2353 [01:49<00:00, 21.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train deep features shape: (5488, 2049)\n",
      "Test deep features shape: (2353, 2049)\n",
      "Deep features extracted successfully for both sets!\n"
     ]
    }
   ],
   "source": [
    "# start to do extraction for train and test set simultaneously\n",
    "# load training metadata\n",
    "print(\"Loading training metadata...\")\n",
    "train_metadata = pd.read_csv(\"/Users/xingzhidu/Desktop/ML/ML A2/dataset/train/train_metadata.csv\")\n",
    "print(f\"Loaded train metadata for {len(train_metadata)} images\")\n",
    "\n",
    "print(\"Loading test metadata...\")\n",
    "test_metadata = pd.read_csv(\"/Users/xingzhidu/Desktop/ML/ML A2/dataset/test/test_metadata.csv\")\n",
    "print(f\"Loaded test metadata for {len(test_metadata)} images\")\n",
    "\n",
    "# get image paths\n",
    "train_image_paths = train_metadata['image_path'].tolist()\n",
    "test_image_paths = test_metadata['image_path'].tolist()\n",
    "\n",
    "train_base_path = \"/Users/xingzhidu/Desktop/ML/ML A2/dataset/train\"\n",
    "test_base_path = \"/Users/xingzhidu/Desktop/ML/ML A2/dataset/test\"\n",
    "\n",
    "print(f\"Processing {len(train_image_paths)} training images and {len(test_image_paths)} test images...\")\n",
    "\n",
    "# extract new features for training set\n",
    "print(\"Processing training set...\")\n",
    "train_new_features_data = extract_new_features_for_images(train_image_paths, train_base_path, \"Train\")\n",
    "\n",
    "# extract new features for test set\n",
    "print(\"Processing test set...\")\n",
    "test_new_features_data = extract_new_features_for_images(test_image_paths, test_base_path, \"Test\")\n",
    "\n",
    "# create column names for new features\n",
    "hog_digit_cols = [f'hog_digit_{i}' for i in range(36)]\n",
    "projection_cols = [f'h_proj_{i}' for i in range(5)] + [f'v_proj_{i}' for i in range(5)]\n",
    "lbp_cols = [f'lbp_{i}' for i in range(10)]\n",
    "new_feature_cols = ['image_path'] + hog_digit_cols + projection_cols + lbp_cols\n",
    "\n",
    "# ceate DataFrames for new features\n",
    "train_new_features_df = pd.DataFrame(train_new_features_data, columns=new_feature_cols)\n",
    "test_new_features_df = pd.DataFrame(test_new_features_data, columns=new_feature_cols)\n",
    "\n",
    "print(f\"Train new features shape: {train_new_features_df.shape}\")\n",
    "print(f\"Test new features shape: {test_new_features_df.shape}\")\n",
    "print(\"New features extracted successfully for both sets!\")\n",
    "\n",
    "# extract deep features\n",
    "\n",
    "print(\"Loading pre-trained ResNet50 model...\")\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, pooling='avg')\n",
    "\n",
    "# extract deep features for training set\n",
    "print(\"Processing training set...\")\n",
    "train_deep_features_data = extract_deep_features_for_images(train_image_paths, train_base_path, base_model, \"Train\")\n",
    "\n",
    "# extract deep features for test set\n",
    "print(\"Processing test set...\")\n",
    "test_deep_features_data = extract_deep_features_for_images(test_image_paths, test_base_path, base_model, \"Test\")\n",
    "\n",
    "# create column names for deep features\n",
    "deep_feature_cols = ['image_path'] + [f'deep_feature_{i}' for i in range(2048)]\n",
    "\n",
    "# create DataFrames for deep features\n",
    "train_deep_features_df = pd.DataFrame(train_deep_features_data, columns=deep_feature_cols)\n",
    "test_deep_features_df = pd.DataFrame(test_deep_features_data, columns=deep_feature_cols)\n",
    "\n",
    "print(f\"Train deep features shape: {train_deep_features_df.shape}\")\n",
    "print(f\"Test deep features shape: {test_deep_features_df.shape}\")\n",
    "print(\"Deep features extracted successfully for both sets!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2629122c-6a38-436f-911a-e147fae9e98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features saved to: /train/new_features.csv and /train/deep_features.csv\n",
      "Test features saved to: /test/new_features.csv and /test/deep_features.csv\n",
      "\n",
      "=== Feature Summary ===\n",
      "New Features Set:\n",
      "  - HOG on Digit ROI: 36 features\n",
      "  - Projection Profiles: 10 features\n",
      "  - Local Binary Patterns: 10 features\n",
      "  - Total: 56 features\n",
      "\n",
      "Deep Features Set:\n",
      "  - ResNet50 features: 2048 features\n",
      "\n",
      "Dataset sizes:\n",
      "  - Training: 5488 samples\n",
      "  - Test: 2353 samples\n"
     ]
    }
   ],
   "source": [
    "# save all extracted feature results\n",
    "# save training features\n",
    "train_new_features_df.to_csv(\"/Users/xingzhidu/Desktop/ML/ML A2/dataset/train/new_features.csv\", index=False)\n",
    "train_deep_features_df.to_csv(\"/Users/xingzhidu/Desktop/ML/ML A2/dataset/train/deep_features.csv\", index=False)\n",
    "\n",
    "# save test features\n",
    "test_new_features_df.to_csv(\"/Users/xingzhidu/Desktop/ML/ML A2/dataset/test/new_features.csv\", index=False)\n",
    "test_deep_features_df.to_csv(\"/Users/xingzhidu/Desktop/ML/ML A2/dataset/test/deep_features.csv\", index=False)\n",
    "\n",
    "print(\"Training features saved to: /train/new_features.csv and /train/deep_features.csv\")\n",
    "print(\"Test features saved to: /test/new_features.csv and /test/deep_features.csv\")\n",
    "\n",
    "# display the feature summary and analysis\n",
    "print(\"\\n=== Feature Summary ===\")\n",
    "print(f\"New Features Set:\")\n",
    "print(f\"  - HOG on Digit ROI: {len(hog_digit_cols)} features\")\n",
    "print(f\"  - Projection Profiles: {len(projection_cols)} features\")\n",
    "print(f\"  - Local Binary Patterns: {len(lbp_cols)} features\")\n",
    "print(f\"  - Total: {len(hog_digit_cols) + len(projection_cols) + len(lbp_cols)} features\")\n",
    "\n",
    "print(f\"\\nDeep Features Set:\")\n",
    "print(f\"  - ResNet50 features: {2048} features\")\n",
    "\n",
    "print(f\"\\nDataset sizes:\")\n",
    "print(f\"  - Training: {len(train_image_paths)} samples\")\n",
    "print(f\"  - Test: {len(test_image_paths)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef59ac3a-ab0c-4aa8-ad1d-e0e3c1a46dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Quick Analysis of Training Features ===\n",
      "Training New features statistics:\n",
      "Mean: 0.4937\n",
      "Std: 0.3265\n",
      "Min: 0.0000\n",
      "Max: 64.0000\n",
      "\n",
      "Training Deep features statistics:\n",
      "Mean: 0.4094\n",
      "Std: 0.4903\n",
      "Min: 0.0000\n",
      "Max: 22.7477\n",
      "\n",
      "Missing values:\n",
      "  - Train new features: 0\n",
      "  - Train deep features: 0\n",
      "  - Test new features: 0\n",
      "  - Test deep features: 0\n"
     ]
    }
   ],
   "source": [
    "# quick analysis of training features\n",
    "print(\"\\n=== Quick Analysis of Training Features ===\")\n",
    "train_new_features_numeric = train_new_features_df.drop('image_path', axis=1)\n",
    "train_deep_features_numeric = train_deep_features_df.drop('image_path', axis=1)\n",
    "\n",
    "print(f\"Training New features statistics:\")\n",
    "print(f\"Mean: {train_new_features_numeric.mean().mean():.4f}\")\n",
    "print(f\"Std: {train_new_features_numeric.std().mean():.4f}\")\n",
    "print(f\"Min: {train_new_features_numeric.min().min():.4f}\")\n",
    "print(f\"Max: {train_new_features_numeric.max().max():.4f}\")\n",
    "\n",
    "print(f\"\\nTraining Deep features statistics:\")\n",
    "print(f\"Mean: {train_deep_features_numeric.mean().mean():.4f}\")\n",
    "print(f\"Std: {train_deep_features_numeric.std().mean():.4f}\")\n",
    "print(f\"Min: {train_deep_features_numeric.min().min():.4f}\")\n",
    "print(f\"Max: {train_deep_features_numeric.max().max():.4f}\")\n",
    "\n",
    "# check for missing values\n",
    "missing_train_new = train_new_features_numeric.isnull().sum().sum()\n",
    "missing_train_deep = train_deep_features_numeric.isnull().sum().sum()\n",
    "missing_test_new = test_new_features_df.drop('image_path', axis=1).isnull().sum().sum()\n",
    "missing_test_deep = test_deep_features_df.drop('image_path', axis=1).isnull().sum().sum()\n",
    "\n",
    "print(f\"\\nMissing values:\")\n",
    "print(f\"  - Train new features: {missing_train_new}\")\n",
    "print(f\"  - Train deep features: {missing_train_deep}\")\n",
    "print(f\"  - Test new features: {missing_test_new}\")\n",
    "print(f\"  - Test deep features: {missing_test_deep}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5f306dd-14cf-492b-b9bf-562e1e0f2737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Quick Analysis of test Features ===\n",
      "Training New features statistics:\n",
      "Mean: 0.4853\n",
      "Std: 0.3266\n",
      "Min: 0.0000\n",
      "Max: 59.0000\n",
      "\n",
      "Training Deep features statistics:\n",
      "Mean: 0.4086\n",
      "Std: 0.4907\n",
      "Min: 0.0000\n",
      "Max: 21.1844\n"
     ]
    }
   ],
   "source": [
    "# quick analysis of test features same as the training feature\n",
    "print(\"\\n=== Quick Analysis of test Features ===\")\n",
    "test_new_features_numeric = test_new_features_df.drop('image_path', axis=1)\n",
    "test_deep_features_numeric = test_deep_features_df.drop('image_path', axis=1)\n",
    "\n",
    "print(f\"Training New features statistics:\")\n",
    "print(f\"Mean: {test_new_features_numeric.mean().mean():.4f}\")\n",
    "print(f\"Std: {test_new_features_numeric.std().mean():.4f}\")\n",
    "print(f\"Min: {test_new_features_numeric.min().min():.4f}\")\n",
    "print(f\"Max: {test_new_features_numeric.max().max():.4f}\")\n",
    "\n",
    "print(f\"\\nTraining Deep features statistics:\")\n",
    "print(f\"Mean: {test_deep_features_numeric.mean().mean():.4f}\")\n",
    "print(f\"Std: {test_deep_features_numeric.std().mean():.4f}\")\n",
    "print(f\"Min: {test_deep_features_numeric.min().min():.4f}\")\n",
    "print(f\"Max: {test_deep_features_numeric.max().max():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ab8bb6-2a5c-4136-a27f-1f413c853efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we find extracted features from  training dataset and test set have very similar distribution\n",
    "# that means our extraction is really great and consistent\n",
    "# our predicitons on test data in the future will be consistent as well"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
